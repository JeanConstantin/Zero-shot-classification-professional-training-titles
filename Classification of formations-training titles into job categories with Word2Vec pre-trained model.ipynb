{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading and fitting NLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this first part, we load a NLP model with word vectors trained on the french internet. A thesaurus which maps compentencies to words describing them the best is then included into the model to correct the word vectors in order to better represent our field which is the labor market, compentencies, jobs and education."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thesaurus preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A thesaurus specific to the labor market and professional skills is uploaded. It will be used to fine-tune the pre-trained Word2Vec model.\n",
    "thesaurus = pd.read_csv('base_thesaurus_competence.csv', sep=';')[['complabel', 'complem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "thesaurus['sentence'] = thesaurus['complabel'] + '|' + thesaurus['complem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "thesaurus['sentence'] = thesaurus['sentence'].str.split('|')\n",
    "thesaurus['sentence'] = thesaurus['sentence'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "thesaurus_sentence = thesaurus['sentence'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning functions : caps, punctuations, stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for Lowercase, Remove parenthesis, Remove numbers, Remove punctuation and stopwords\n",
    "\n",
    "def prep_text(string):\n",
    "    \n",
    "    from nltk.corpus import stopwords\n",
    "    french_stopwords_list = stopwords.words('french')\n",
    "    \n",
    "    treated = str(string)\n",
    "    treated = treated.lower()\n",
    "    treated = treated.replace(r'\\(.*?\\)', '')\n",
    "    treated = treated.replace(r'\\[.*?\\]', '')\n",
    "    treated = treated.replace(r'[0-9]+', '')\n",
    "    treated = treated.replace(r'[,\\.:/]+', ' ')\n",
    "    treated = treated.replace('\"', \"\")\n",
    "    treated = treated.split(' ')\n",
    "    treated = [word for word in treated if word not in french_stopwords_list]\n",
    "    treated = ' '.join(treated)\n",
    "    \n",
    "    return treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "thesaurus_sentence = [prep_text(elem) for elem in thesaurus_sentence]\n",
    "#thesaurus_sentence is a list in which every element is composed of the thesaurus described competences and the words used to describe them.\n",
    "#Individual words are separated by spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain specific knowledge pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "training_title = pd.read_excel('training_titles_list.xlsx')\n",
    "job_title = pd.read_excel('job_title_list.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The diploma file needs to be pre-treated to remove words that are not meaningful => remove master, titre, spe, ...\n",
    "training_title['intitule_light'] = training_title['formation'].str.replace('MASTERE', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('MASTER', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('TITRE PRO', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('TITRE', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('LICENCE PRO', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('LICENCE', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('GRADE', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('DUT', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('NIVEAU', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('DIPLOME', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('BAC PRO', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('BTSA', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('BTS', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('BP', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('BTM', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('BM', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('BREVET PROFESSIONNEL', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('DIP', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('OPTION', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('RNCP', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('MC', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('DIPLOME DE', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('DIPLOME D', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('DEUST', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('TP', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title['text_training'] = job_title['Branche'] + ' ' + job_title['Métier'] + ' ' + job_title['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_title_train = training_title['intitule_light'].to_list()\n",
    "training_title_train = [prep_text(elem) for elem in training_title_train]\n",
    "\n",
    "job_title_train = job_title['text_training'].to_list()\n",
    "job_title_train = [prep_text(elem) for elem in job_title_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = thesaurus_sentence + training_title_train + job_title_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning pre trained Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a model based on the thesaurus => The thesaurus is a file linking a list of compentencies to pertinent words describing them\n",
    "#A model is initiated with the words present in the thesaurus\n",
    "thesaurus_sentence = [elem.split(' ') for elem in thesaurus_sentence]\n",
    "\n",
    "model_tuned = Word2Vec(size=200, min_count=1, sg=0, min_alpha=1)\n",
    "model_tuned.build_vocab(text_train)\n",
    "total_examples = model_tuned.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pre trained vectors => A model with pre-trained word vectors\n",
    "#French pre trained vectors available here :  http://fauconnier.github.io/#data\n",
    "model_pretrained = KeyedVectors.load_word2vec_format(\"pre-trained embeddings/Word2Vec/frWac_non_lem_no_postag_no_phrase_200_cbow_cut0.bin\", binary=True, unicode_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine pre-trained model to the thesaurus model\n",
    "model_tuned.build_vocab([list(model_pretrained.vocab.keys())], update=True)\n",
    "model_tuned.intersect_word2vec_format(\"pre-trained embeddings/Word2Vec/frWac_non_lem_no_postag_no_phrase_200_cbow_cut0.bin\", binary=True, lockf=1.0, unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-75-c69a013ab683>:2: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  model_tuned.train(text_train, total_examples=total_examples, epochs=model_tuned.iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7551924, 8414220)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model with the thesaurus\n",
    "#This is done so that word vector's meaning are corrected to better represent the field of compentencies and labor market\n",
    "model_tuned.train(text_train, total_examples=total_examples, epochs=model_tuned.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "model_tuned.save('pre-trained embeddings/Word2Vec/fine-tuned-model/word_embedding_thesaurus.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Matching formations/training titles with categories/job titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this second part, we compute a vector representation for each formations/training titles and categories/job titles by finding the word vectors corresponding to each words, and then averaging them with each words' TF-IDF scores. A similarity score (cosine) is then computed between each formation/training titles and the categories. The categories with the lowest distances are kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "training_title = pd.read_excel('training_title.xlsx')\n",
    "job_title = pd.read_excel('jov_title.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The diploma file needs to be pre-treated => remove master, titre, spe, ...\n",
    "#The diploma file needs to be pre-treated => remove master, titre, spe, ...\n",
    "training_title['intitule_light'] = training_title['formation'].str.replace('MASTERE', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('MASTER', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('TITRE PRO', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('TITRE', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('LICENCE PRO', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('LICENCE', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('GRADE', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('DUT', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('NIVEAU', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('DIPLOME', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('BAC PRO', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('BTSA', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('BTS', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('BP', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('BTM', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('BM', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('BREVET PROFESSIONNEL', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('DIP', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('OPTION', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('RNCP', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('MC', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('DIPLOME DE', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('DIPLOME D', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('DEUST', '')\n",
    "training_title['intitule_light'] = training_title['intitule_light'].str.replace('TP', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title['categories_branche_metier'] = job_title['Branche'] + ' ' + job_title['Métier']\n",
    "job_title['categories_metier_desc'] = job_title['Métier'] + ' ' + job_title['Description']\n",
    "job_title['categories_branche_metier_desc'] = job_title['Branche'] + ' ' + job_title['Métier'] + ' ' + job_title['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_title_data = training_title['intitule_light'].to_list()\n",
    "training_title_data = [prep_text(elem) for elem in training_title_data]\n",
    "\n",
    "job_title_metier = job_title['categories_branche_metier'].to_list()\n",
    "categories_branche_metier = [prep_text(elem) for elem in job_title_metier ]\n",
    "\n",
    "job_title_metier_desc = job_title['categories_metier_desc'].to_list()\n",
    "job_title_metier_desc = [prep_text(elem) for elem in job_title_metier_desc]\n",
    "\n",
    "job_title_branche_metier_desc = job_title['categories_branche_metier_desc'].to_list()\n",
    "job_title_branche_metier_desc = [prep_text(elem) for elem in job_title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title['key_merge_cat'] = job_title['categories_branche_metier_desc'].apply(lambda x: prep_text(x))\n",
    "training_title['key_merge_dip'] = training_title['intitule_light'].apply(lambda x: prep_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pretrained model which contains the word vectors\n",
    "from gensim.models import KeyedVectors\n",
    "model_pretrained = KeyedVectors.load('pre-trained embeddings/Word2Vec/fine-tuned-model/word_embedding_thesaurus.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classification():\n",
    "    \n",
    "    def __init__(self, categories, data, model):\n",
    "        self.categories = categories\n",
    "        self.data = data\n",
    "        self.model = model\n",
    "        \n",
    "        #Instance of a tfidf vectorizer fitted on all the text\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        text_total = self.data + self.categories\n",
    "        tfidf_vectorizer.fit(text_total)\n",
    "        self.vocabulary = tfidf_vectorizer.vocabulary_\n",
    "\n",
    "        #TfIdf vectorization of the data to be classified and the categories\n",
    "        self.data_tfidf = tfidf_vectorizer.transform(self.data)\n",
    "        self.categories_tfidf = tfidf_vectorizer.transform(self.categories)\n",
    "\n",
    "        #Vectorization of the sentences : categories\n",
    "        #Vectorization : find matching pre-trained embeddings, and average them over the sentences with tfidf weights\n",
    "        import numpy as np\n",
    "        categories_average_embedding = np.zeros((len(self.categories), self.model.vector_size))\n",
    "        nb_sentence = 0\n",
    "        \n",
    "        for sentence in self.categories:\n",
    "            tfidf_score_total = 0\n",
    "            sentence_vector = np.zeros((1, self.model.vector_size))\n",
    "            \n",
    "            for word in sentence.split(' '):\n",
    "                try:\n",
    "                    score_tfidf = self.categories_tfidf[nb_sentence,self.vocabulary[word]]\n",
    "                    word_vector = self.model.wv[word].reshape((1, self.model.vector_size)) * score_tfidf\n",
    "                    sentence_vector += word_vector\n",
    "                    tfidf_score_total += score_tfidf\n",
    "                except KeyError:\n",
    "                    pass\n",
    "                \n",
    "            sentence_vector = sentence_vector / tfidf_score_total\n",
    "            categories_average_embedding[nb_sentence,:] = sentence_vector\n",
    "            nb_sentence += 1\n",
    "            \n",
    "        self.categories_sentence_vector = categories_average_embedding\n",
    "        \n",
    "        \n",
    "        #Vectorization of the sentences : data\n",
    "        #Vectorization : find matching pre-trained embeddings, and average them over the sentences with tfidf weights\n",
    "        data_average_embedding = np.zeros((len(self.data), self.model.vector_size))\n",
    "        nb_sentence = 0\n",
    "        \n",
    "        for sentence in self.data:\n",
    "            tfidf_score_total = 0\n",
    "            sentence_vector = np.zeros((1, self.model.vector_size))\n",
    "            \n",
    "            for word in sentence.split(' '):\n",
    "                try:\n",
    "                    score_tfidf = self.data_tfidf[nb_sentence,self.vocabulary[word]]\n",
    "                    word_vector = self.model.wv[word].reshape((1, self.model.vector_size)) * score_tfidf\n",
    "                    sentence_vector += word_vector\n",
    "                    tfidf_score_total += score_tfidf\n",
    "                except KeyError:\n",
    "                    pass\n",
    "                \n",
    "            sentence_vector = sentence_vector / tfidf_score_total\n",
    "            data_average_embedding[nb_sentence,:] = sentence_vector\n",
    "            nb_sentence += 1\n",
    "            \n",
    "        self.data_sentence_vector = data_average_embedding\n",
    "    \n",
    "    #A function to find the most similar elements between the data and the categories is defined\n",
    "    #A distance score is computed for each possible pair => the distance can either be cosine or euclidian\n",
    "    #Arguments : k_nearest_items = find the k elements the most similar to the categories\n",
    "    #Arguments : standard_deviation = the matched item must have a distance that is at least smaller than the x times the standard deviation of distances within one category\n",
    "    def matching(self,k_nearest_items, x_standard_deviation, distance_type):\n",
    "        if distance_type == 'cosine_similarity':\n",
    "            from scipy import spatial\n",
    "            df_final = pd.DataFrame(columns=['categories', 'items', 'distance', 'rank'])\n",
    "            \n",
    "        #Iteration over each sentence to be classfied, for each sentence iterated in the data all categories are also iterated\n",
    "        #In this way, all sentence to classify are compared with all categories            \n",
    "            for row_cat_nb in range(len(self.categories)):\n",
    "                df_provisoire = pd.DataFrame(columns=['categories', 'items', 'distance'])\n",
    "                \n",
    "                for row_data_nb in range(len(self.data)):\n",
    "                    distance = spatial.distance.cosine(self.categories_sentence_vector[row_cat_nb,:], self.data_sentence_vector[row_data_nb,:])\n",
    "                    dic_provisoire = {'categories':self.categories[row_cat_nb], 'items':self.data[row_data_nb], 'distance':distance}\n",
    "                    df_provisoire = df_provisoire.append(dic_provisoire, ignore_index=True)\n",
    "                \n",
    "                df_provisoire_min = df_provisoire.iloc[df_provisoire['distance'].argmin()]\n",
    "\n",
    "                df_provisoire = df_provisoire[df_provisoire['distance'] < (df_provisoire['distance'].mean() - df_provisoire['distance'].std()* x_standard_deviation)]\n",
    "                df_provisoire = df_provisoire.append(df_provisoire_min)\n",
    "                df_provisoire = df_provisoire.drop_duplicates()\n",
    "                \n",
    "                df_provisoire = df_provisoire.sort_values(by='distance', ascending=True)\n",
    "                df_provisoire = df_provisoire.reset_index(drop=True)\n",
    "                df_provisoire['rank'] = df_provisoire.index.values.astype(int) + 1\n",
    "                df_provisoire = df_provisoire[df_provisoire['rank'] <= k_nearest_items]\n",
    "                print(df_provisoire)\n",
    "\n",
    "                df_final = df_final.append(df_provisoire)\n",
    "\n",
    "            return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-83-c73f8e5c8423>:63: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sentence_vector = sentence_vector / tfidf_score_total\n"
     ]
    }
   ],
   "source": [
    "#Initiate an instance of the Classification Class\n",
    "matching_tu = classification(job_title_branche_metier_desc, training_title_data, model_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the matching function\n",
    "resultats_tu = matching_tu.matching(30,2,'cosine_similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the results df with the original dataframe to recover the original unchanged titles\n",
    "resultat_tu_label = resultats_tu.merge(training_title, left_on='items', right_on='key_merge_dip')\n",
    "resultat_tu_label = resultat_tu_label.merge(job_title, left_on='categories', right_on='key_merge_cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results df to an excel file\n",
    "resultat_tu_label.to_excel('classification_result.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
